{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f5dc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from dataset import PolarDecDataset  # your dataset class\n",
    "from models.wrappers.mamba_32bits import MambaPolarDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a224c9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "N = 32  \n",
    "CONFIG_NO = 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff0d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_curriculum = [\n",
    "    10, 10,\n",
    "    9, 9,\n",
    "    8,\n",
    "    7,\n",
    "    6, 6,\n",
    "    5,\n",
    "    4,\n",
    "    3,\n",
    "    0, 0,\n",
    "    -3,\n",
    "    -6,\n",
    "    -10\n",
    "]\n",
    "\n",
    "test_snr_list = [10, 6, 0, -3, -6, -10]\n",
    "\n",
    "\n",
    "num_train_samples = 100000   # large dataset for low BER\n",
    "num_test_samples  = 320_000    \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b83b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PolarDecDataset(\n",
    "    snr_list=[10],  \n",
    "    num_samples=num_train_samples,\n",
    "    seq_length=N\n",
    ")\n",
    "\n",
    "test_dataset = PolarDecDataset(\n",
    "    snr_list=test_snr_list,\n",
    "    num_samples=num_test_samples,\n",
    "    seq_length=N\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bcfdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaPolarDecoder(\n",
    "    d_model=64,\n",
    "    num_layer_encoder=1,\n",
    "    num_layers_bimamba_block=12,\n",
    "    seq_len=N,\n",
    "    d_state=32,\n",
    "    d_conv=6,\n",
    "    expand=2,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89de499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25cdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(frozen, target, pred):\n",
    "    mask = (frozen != 1)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    return loss_fn(pred[mask], target[mask])\n",
    "\n",
    "def compute_ber(pred, target):\n",
    "    bits = (torch.sigmoid(pred) > 0.5).int()\n",
    "    return (bits != target.int()).sum().item() / target.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61d4703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_save_ber(\n",
    "    model,\n",
    "    device,\n",
    "    snr_values,\n",
    "    msg_bit_sizes=[8,16,24],\n",
    "    seq_length=32,\n",
    "    num_samples=3200,\n",
    "    batch_size=32,\n",
    "    config_no=0,\n",
    "    epoch=0,\n",
    "    save_dir=\"src/evaluation\",\n",
    "):\n",
    "    import json\n",
    "    from torch.utils.data import DataLoader\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    config_dir = os.path.join(save_dir, f\"config_{config_no}\")\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "    eval_results = {}\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for each_snr in snr_values:\n",
    "            print(f\"\\nEvaluating for SNR = {each_snr} dB\\n\")\n",
    "            snr_key = f\"{each_snr}_snr\"\n",
    "            eval_results[snr_key] = {}\n",
    "            ber_list = []\n",
    "\n",
    "            for msg_size in msg_bit_sizes:\n",
    "                total_msg_bit_errors = 0\n",
    "                total_frozen_bit_errors = 0\n",
    "                total_msg_bits = 0\n",
    "                total_frozen_bits = 0\n",
    "\n",
    "                test_set = PolarDecDataset(\n",
    "                    snr_list=[each_snr],\n",
    "                    num_samples=num_samples,\n",
    "                    fixed_msg_bit_size=msg_size,\n",
    "                    seq_length=seq_length\n",
    "                )\n",
    "\n",
    "                test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                for llrs, frozen_tensor, snr_tensor, target_tensor in test_loader:\n",
    "                    llrs = llrs.to(device).float()\n",
    "                    frozen_tensor = frozen_tensor.to(device).long()\n",
    "                    target_tensor = target_tensor.to(device).long()\n",
    "\n",
    "                    logits = model(llrs, frozen_tensor, snr_tensor.to(device))\n",
    "                    predicted = (logits > 0).long()\n",
    "\n",
    "                    mask_msg = (frozen_tensor == 1)\n",
    "                    mask_frozen = (frozen_tensor == 0)\n",
    "\n",
    "                    msg_target = target_tensor[mask_msg]\n",
    "                    msg_pred = predicted[mask_msg]\n",
    "\n",
    "                    frozen_target = target_tensor[mask_frozen]\n",
    "                    frozen_pred = predicted[mask_frozen]\n",
    "\n",
    "                    total_msg_bit_errors += (msg_target != msg_pred).sum().item()\n",
    "                    total_frozen_bit_errors += (frozen_target != frozen_pred).sum().item()\n",
    "\n",
    "                    total_msg_bits += msg_target.numel()\n",
    "                    total_frozen_bits += frozen_target.numel()\n",
    "\n",
    "                total_bits = total_msg_bits + total_frozen_bits\n",
    "                total_error_bits = total_msg_bit_errors + total_frozen_bit_errors\n",
    "\n",
    "                avg_net_ber = total_error_bits / total_bits\n",
    "                avg_msg_ber = total_msg_bit_errors / total_msg_bits if total_msg_bits > 0 else 0.0\n",
    "                avg_frozen_ber = total_frozen_bit_errors / total_frozen_bits if total_frozen_bits > 0 else 0.0\n",
    "\n",
    "                print(f\"    Net BER     : {avg_net_ber:.6e}\")\n",
    "                print(f\"    Msg BER     : {avg_msg_ber:.6e}\")\n",
    "                print(f\"    Frozen BER  : {avg_frozen_ber:.6e}\\n\")\n",
    "\n",
    "                eval_results[snr_key][str(msg_size)] = {\n",
    "                    \"average_net_bit_error_rate\": avg_net_ber,\n",
    "                    \"average_msg_bit_error_rate\": avg_msg_ber,\n",
    "                    \"average_frozen_bit_error_rate\": avg_frozen_ber,\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"num_samples\": num_samples,\n",
    "                    \"total_bits\": total_bits,\n",
    "                    \"total_error_bits\": total_error_bits,\n",
    "                    \"total_msg_bits\": total_msg_bits,\n",
    "                    \"total_frozen_bits\": total_frozen_bits,\n",
    "                }\n",
    "\n",
    "                ber_list.append(avg_net_ber)\n",
    "\n",
    "            eval_results[snr_key][\"overall_ber\"] = sum(ber_list) / len(ber_list)\n",
    "            print(f\"  Overall BER for SNR {each_snr}: {eval_results[snr_key]['overall_ber']:.6e}\")\n",
    "\n",
    "    json_file_name = os.path.join(config_dir, f\"epoch_{epoch+1}_snr_{'_'.join(map(str, snr_values))}.json\")\n",
    "    with open(json_file_name, \"w\") as f:\n",
    "        json.dump(eval_results, f, indent=4)\n",
    "    print(f\"\\nBER results saved to {json_file_name}\")\n",
    "\n",
    "    return eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6b4b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_ber(preds, target):\n",
    "#     pred_bits = (torch.sigmoid(preds) > 0.5).int()\n",
    "#     total_bits = target.numel()\n",
    "#     error_bits = (pred_bits != target.int()).sum().item()\n",
    "#     return error_bits / total_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc28803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(batches==1000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        channel, frozen, snr, target = batch\n",
    "        channel = channel.float().to(device)\n",
    "        frozen  = frozen.int().to(device)\n",
    "        target  = target.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(channel, frozen, snr.float().to(device))\n",
    "        loss = calculate_loss(frozen, target, out)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        \n",
    "        if (i + 1) % batches== 0:\n",
    "            last_loss = running_loss / batches\n",
    "            print(f'  Batch {i+1} Average Loss: {last_loss:.6f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    return last_loss \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    best_val_ber = 1.0\n",
    "    active_snrs = [10]\n",
    "\n",
    "    # --- Pretraining at 10 dB ---\n",
    "    print(\"\\nSNR = 10 dB\")\n",
    "    train_dataset.snr_list = [10]\n",
    "\n",
    "    for epoch in range(10):\n",
    "        print(f\"Epoch {epoch+1}/10\")\n",
    "        avg_loss = train_one_epoch(print_every=1000)\n",
    "\n",
    "        # Track best loss in this 5-epoch pretraining block\n",
    "        if epoch % 5 == 0:\n",
    "            best_loss_in_block = avg_loss\n",
    "            best_epoch_in_block = epoch\n",
    "        else:\n",
    "            if avg_loss < best_loss_in_block:\n",
    "                best_loss_in_block = avg_loss\n",
    "                best_epoch_in_block = epoch\n",
    "\n",
    "        # Save after 5 epochs of pretraining\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"\\nSaving model after 5 epochs (best training loss in block: {best_loss_in_block:.6e})\")\n",
    "            \n",
    "            # Compute BER over test SNRs\n",
    "            val_results = calc_save_ber(\n",
    "                model,\n",
    "                device,\n",
    "                snr_values=test_snr_list,\n",
    "                msg_bit_sizes=[8,16,24],\n",
    "                num_samples=3200,\n",
    "                batch_size=32,\n",
    "                config_no=CONFIG_NO,\n",
    "                epoch=best_epoch_in_block,\n",
    "                save_dir=\"src/evaluation\"\n",
    "            )\n",
    "\n",
    "            avg_vloss = np.mean([val_results[f\"{s}_snr\"][\"overall_ber\"] for s in test_snr_list])\n",
    "\n",
    "            # Save checkpoint of the epoch with best training loss in this 5-epoch block\n",
    "            model_dir = f\"./checkpoints/config_{CONFIG_NO}\"\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "            model_path = f\"{model_dir}/model_best_block_epoch_{best_epoch_in_block+1}.pt\"\n",
    "\n",
    "            torch.save({\n",
    "                \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "                \"model_config\": {\n",
    "                    \"d_model\": model.d_model,\n",
    "                    \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                    \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                    \"seq_len\": model.seq_len,\n",
    "                    \"d_state\": model.d_state,\n",
    "                    \"d_conv\": model.d_conv,\n",
    "                    \"expand\": model.expand,\n",
    "                },\n",
    "                \"epoch\": best_epoch_in_block + 1,\n",
    "                \"train_loss\": best_loss_in_block,\n",
    "                \"val_loss\": avg_vloss,\n",
    "                \"state_dict\": model.state_dict()\n",
    "            }, model_path)\n",
    "            print(f\"Saved model checkpoint for best loss in block: {model_path}\")\n",
    "\n",
    "    # --- Curriculum Training ---\n",
    "    for snr in snr_curriculum:\n",
    "        print(f\"\\nValidation BEFORE adding new SNR {snr}\")\n",
    "        val_results = calc_save_ber(\n",
    "            model,\n",
    "            device,\n",
    "            snr_values=test_snr_list,\n",
    "            msg_bit_sizes=[8,16,24],\n",
    "            num_samples=3200,\n",
    "            batch_size=32,\n",
    "            config_no=CONFIG_NO,\n",
    "            epoch=0,\n",
    "            save_dir=\"src/evaluation\"\n",
    "        )\n",
    "        avg_vloss = np.mean([val_results[f\"{s}_snr\"][\"overall_ber\"] for s in test_snr_list])\n",
    "        print(f\"Validation BER before adding new SNR: {avg_vloss:.6e}\")\n",
    "\n",
    "        if snr not in active_snrs:\n",
    "            active_snrs.append(snr)\n",
    "        train_dataset.snr_list = active_snrs\n",
    "        print(f\"\\nTraining with SNRs: {active_snrs}\")\n",
    "\n",
    "        # 5-epoch block for this SNR\n",
    "        best_loss_in_block = float('inf')\n",
    "        best_epoch_in_block = 0\n",
    "        for epoch in range(5):\n",
    "            print(f\"Epoch {epoch+1}/5 for SNR {snr}\")\n",
    "            avg_loss = train_one_epoch(print_every=1000)\n",
    "\n",
    "            # Track best training loss\n",
    "            if avg_loss < best_loss_in_block:\n",
    "                best_loss_in_block = avg_loss\n",
    "                best_epoch_in_block = epoch\n",
    "\n",
    "        # After 5 epochs, save the model with lowest training loss in this block\n",
    "        print(f\"\\nSaving model for SNR {snr} with best training loss in block: {best_loss_in_block:.6e}\")\n",
    "        val_results = calc_save_ber(\n",
    "            model,\n",
    "            device,\n",
    "            snr_values=test_snr_list,\n",
    "            msg_bit_sizes=[8,16,24],\n",
    "            num_samples=3200,\n",
    "            batch_size=32,\n",
    "            config_no=CONFIG_NO,\n",
    "            epoch=best_epoch_in_block,\n",
    "            save_dir=\"src/evaluation\"\n",
    "        )\n",
    "        avg_vloss = np.mean([val_results[f\"{s}_snr\"][\"overall_ber\"] for s in test_snr_list])\n",
    "\n",
    "        model_dir = f\"./checkpoints/config_{CONFIG_NO}\"\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        model_path = f\"{model_dir}/model_best_block_epoch_{best_epoch_in_block+1}_snr_{snr}.pt\"\n",
    "\n",
    "        torch.save({\n",
    "            \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "            \"model_config\": {\n",
    "                \"d_model\": model.d_model,\n",
    "                \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                \"seq_len\": model.seq_len,\n",
    "                \"d_state\": model.d_state,\n",
    "                \"d_conv\": model.d_conv,\n",
    "                \"expand\": model.expand,\n",
    "            },\n",
    "            \"epoch\": best_epoch_in_block + 1,\n",
    "            \"train_loss\": best_loss_in_block,\n",
    "            \"val_loss\": avg_vloss,\n",
    "            \"state_dict\": model.state_dict()\n",
    "        }, model_path)\n",
    "        print(f\"Saved model checkpoint for best loss in block for SNR {snr}: {model_path}\")\n",
    "\n",
    "    print(\"\\nTraining finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17645cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SNR = 10 dB\n",
      "Epoch 1/10\n",
      "Batch 1000/3125, Loss: 0.000012\n",
      "Batch 2000/3125, Loss: 0.000007\n",
      "Batch 3000/3125, Loss: 0.000005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/10\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m train_one_epoch()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m val_ber = \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBER:\u001b[39m\u001b[33m\"\u001b[39m, val_ber)\n\u001b[32m     16\u001b[39m scheduler.step(val_ber)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mvalidate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m         frozen  = frozen.int().to(device)\n\u001b[32m     30\u001b[39m         target  = target.float().to(device)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrozen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m         ber_sum += compute_ber(out, target)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ber_sum / \u001b[38;5;28mlen\u001b[39m(test_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/wrappers/mamba_32bits.py:114\u001b[39m, in \u001b[36mMambaPolarDecoder.forward\u001b[39m\u001b[34m(self, channel_ob_vector, frozen_prior, SNR_db)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# BiMamba encoder stack\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.encoder_layers):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     x_new = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     x = x_new * \u001b[38;5;28mself\u001b[39m.residual_scale + x\n\u001b[32m    116\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.post_norms[idx](x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:164\u001b[39m, in \u001b[36mBiMambaEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# pass through stacked BiMambaBlocks\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     h = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:88\u001b[39m, in \u001b[36mBiMambaBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     87\u001b[39m     out_f = \u001b[38;5;28mself\u001b[39m.forward_branch(x, \u001b[38;5;28mself\u001b[39m.pre_ln_f, \u001b[38;5;28mself\u001b[39m.mamba_f, \u001b[38;5;28mself\u001b[39m.post_ln_f, \u001b[38;5;28mself\u001b[39m.ffn_f, flip_time=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     out_r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_ln_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmamba_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpost_ln_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m * (out_f + out_r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:70\u001b[39m, in \u001b[36mBiMambaBlock.forward_branch\u001b[39m\u001b[34m(self, x, pre_ln, mamba, post_ln, ffn, flip_time)\u001b[39m\n\u001b[32m     67\u001b[39m     x_proc = x\n\u001b[32m     69\u001b[39m h = pre_ln(x_proc)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m h = \u001b[43mmamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m h = \u001b[38;5;28mself\u001b[39m.dropout(h)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_time:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/mamba_ssm/modules/mamba_simple.py:143\u001b[39m, in \u001b[36mMamba.forward\u001b[39m\u001b[34m(self, hidden_states, inference_params)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_proj.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    141\u001b[39m     xz = xz + rearrange(\u001b[38;5;28mself\u001b[39m.in_proj.bias.to(dtype=xz.dtype), \u001b[33m\"\u001b[39m\u001b[33md -> d 1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m A = -\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mA_log\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (d_inner, d_state)\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# In the backward pass we write dx and dz next to each other to avoid torch.cat\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_fast_path \u001b[38;5;129;01mand\u001b[39;00m causal_conv1d_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inference_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# Doesn't support outputting the states\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0539b466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
