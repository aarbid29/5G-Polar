{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589f41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import PolarDecDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from models.wrappers.mamba_32bits import MambaPolarDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85178a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32\n",
    "CONFIG_NO = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6fb613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f1e95",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e1bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_snr_list = [10, 9, 8, 7, 6, 5, 4, 3, 0, -3, -6, -10]\n",
    "train_snr_list = [10]\n",
    "test_snr_list  = [10]\n",
    "\n",
    "dataset = PolarDecDataset(\n",
    "    snr_list=train_snr_list,\n",
    "    num_samples=100000,\n",
    "    seq_length=N\n",
    ")\n",
    "\n",
    "test_set = PolarDecDataset(\n",
    "    snr_list=test_snr_list,\n",
    "    num_samples=3200,\n",
    "    seq_length=N\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbd230",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a2a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaPolarDecoder(\n",
    "    d_model=64,               \n",
    "    num_layer_encoder=1,      \n",
    "    num_layers_bimamba_block=12,  \n",
    "    seq_len=N,\n",
    "    d_state=32,              \n",
    "    d_conv=6,                 \n",
    "    expand=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b5ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"./checkpoints/config_16/model_epoch_11.pt\"\n",
    "# ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "# model.load_state_dictckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20a282",
   "metadata": {},
   "source": [
    "## Minor modification to the Loss Function: Calculates loss only at non frozen positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08030592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(frozen_bit_prior, target_vector, predicted_vector, reliable_only=False):\n",
    "\n",
    "    if reliable_only:\n",
    "        mask = (frozen_bit_prior == 1) \n",
    "        if mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=predicted_vector.device)\n",
    "        # Prevent loss function from crashing when a batch contains no information bits, by safely returning zero loss.\n",
    "        target_vector = target_vector[mask]\n",
    "        predicted_vector = predicted_vector[mask]\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    return loss_fn(predicted_vector, target_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69534924",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=0\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "import os\n",
    "\n",
    "def train(epochs=50):\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Training\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "        # Validation\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(test_dataloader):\n",
    "                vchannel_tensor, vfrozen_tensor, vsnr_tensor, vtarget_tensor = vdata\n",
    "                voutputs = model(\n",
    "                    vchannel_tensor.float().to(device),\n",
    "                    vfrozen_tensor.int().to(device),\n",
    "                    vsnr_tensor.float().to(device)\n",
    "                )\n",
    "                vloss = calculate_loss(\n",
    "                    vfrozen_tensor.to(device), \n",
    "                    vtarget_tensor.to(device), \n",
    "                    voutputs.to(device)\n",
    "                )\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        scheduler.step(avg_vloss)\n",
    "\n",
    "        # Save checkpoint if validation improves\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_dir = f'./checkpoints/config_{CONFIG_NO}'\n",
    "            os.makedirs(model_dir, exist_ok=True)  \n",
    "            model_path = f'{model_dir}/model_epoch_{epoch}.pt'\n",
    "            \n",
    "            torch.save({\n",
    "                \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "                'model_config': {\n",
    "                    \"d_model\": model.d_model,\n",
    "                    \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                    \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                    \"seq_len\": model.seq_len,\n",
    "                    \"d_state\": model.d_state,\n",
    "                    \"d_conv\": model.d_conv,\n",
    "                    \"expand\": model.expand,\n",
    "                },\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_loss,\n",
    "                'val_loss': avg_vloss,\n",
    "                'state_dict': model.state_dict()\n",
    "            }, model_path)\n",
    "\n",
    "    print(\"Training completed. Model available to use\")\n",
    "\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # Extracting tensors\n",
    "        channel_tensor, frozen_tensor, snr_tensor, target_tensor = data\n",
    "        ip1 = channel_tensor.float().to(device)\n",
    "        ip2 = frozen_tensor.int().to(device)\n",
    "        ip3 = snr_tensor.float().to(device)\n",
    "    \n",
    "\n",
    "        op = target_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ip1,ip2 ,ip3 ).to(device)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = calculate_loss(ip2, op, outputs)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/1000\n",
    "            print('  batch {} loss: {}\\n'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3102425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train(epochs=50):\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Training\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "        # Validation\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(test_dataloader):\n",
    "                vchannel_tensor, vfrozen_tensor, vsnr_tensor, vtarget_tensor = vdata\n",
    "                voutputs = model(\n",
    "                    vchannel_tensor.float().to(device),\n",
    "                    vfrozen_tensor.int().to(device),\n",
    "                    vsnr_tensor.float().to(device)\n",
    "                )\n",
    "                vloss = calculate_loss(\n",
    "                    vfrozen_tensor.to(device), \n",
    "                    vtarget_tensor.to(device), \n",
    "                    voutputs.to(device)\n",
    "                )\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        scheduler.step(avg_vloss)\n",
    "\n",
    "        # Save checkpoint if validation improves\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_dir = f'./checkpoints/config_{CONFIG_NO}'\n",
    "            os.makedirs(model_dir, exist_ok=True)  \n",
    "            model_path = f'{model_dir}/model_epoch_{epoch}.pt'\n",
    "            \n",
    "            torch.save({\n",
    "                \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "                'model_config': {\n",
    "                    \"d_model\": model.d_model,\n",
    "                    \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                    \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                    \"seq_len\": model.seq_len,\n",
    "                    \"d_state\": model.d_state,\n",
    "                    \"d_conv\": model.d_conv,\n",
    "                    \"expand\": model.expand,\n",
    "                },\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_loss,\n",
    "                'val_loss': avg_vloss,\n",
    "                'state_dict': model.state_dict()\n",
    "            }, model_path)\n",
    "\n",
    "    print(\"Training completed. Model available to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d589f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epochs)\u001b[39m\n\u001b[32m     32\u001b[39m         total_vbatches += \u001b[32m1\u001b[39m\n\u001b[32m     34\u001b[39m avg_vloss = running_vloss / total_vbatches\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLOSS train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m valid \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_vloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m scheduler.step(avg_vloss)\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Checkpoint\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "train(epochs=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae574987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use your calc_save_ber function\n",
    "# calc_save_ber(\n",
    "#     model=model,\n",
    "#     device=device,\n",
    "#     msg_bit_sizes=[8, 16, 24],\n",
    "#     snr_db=[10, 6, 0, -6, -10],\n",
    "#     num_samples=32_000,\n",
    "#     batch_size=32,\n",
    "#     json_file_name=\"evaluation_model_config_16\"\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
