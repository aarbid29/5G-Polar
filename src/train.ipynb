{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "589f41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataset import PolarDecDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from models.wrappers.mamba_32bits import MambaPolarDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85178a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 32\n",
    "CONFIG_NO = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6fb613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f1e95",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_snr_list = [10, 8, 6, 3, 0, -3, -6, -10]\n",
    "test_snr_list  = [10, 6, 0, -3, -6, -10]\n",
    "\n",
    "dataset = PolarDecDataset(\n",
    "    snr_list=train_snr_list,\n",
    "    num_samples=100000,\n",
    "    seq_length=N\n",
    ")\n",
    "\n",
    "test_set = PolarDecDataset(\n",
    "    snr_list=test_snr_list,\n",
    "    num_samples=3200,\n",
    "    seq_length=N\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdad0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(dataset, batch_size = 32)\n",
    "# test_dataloader = DataLoader(test_set, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbbd230",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a2a925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MambaPolarDecoder(\n",
    "    d_model=32,               \n",
    "    num_layer_encoder=1,      \n",
    "    num_layers_bimamba_block=10,  \n",
    "    seq_len=N,\n",
    "    d_state=32,               \n",
    "    d_conv=6,                 \n",
    "    expand=2\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5ae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/config_16/model_epoch_11.pt\"\n",
    "ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20a282",
   "metadata": {},
   "source": [
    "## Minor modification to the Loss Function: Calculates loss only at non frozen positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05e72cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(frozen_bit_prior, target_vector, predicted_vector,  reliable_only=False):\n",
    "\n",
    "    if reliable_only: \n",
    "     mask = (frozen_bit_prior != 1) \n",
    "     target_vector = target_vector[mask]\n",
    "     predicted_vector = predicted_vector[mask]\n",
    "\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    return loss_fn(predicted_vector, target_vector)\n",
    "    #Defines a custom loss function for polar code decoding, optionally ignoring frozen bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69534924",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5e-6,\n",
    "    weight_decay=0\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "\n",
    "    running_loss = 0\n",
    "    last_loss = 0\n",
    "import os\n",
    "\n",
    "def train(epochs=50):\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Training\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "        # Validation\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(test_dataloader):\n",
    "                vchannel_tensor, vfrozen_tensor, vsnr_tensor, vtarget_tensor = vdata\n",
    "                voutputs = model(\n",
    "                    vchannel_tensor.float().to(device),\n",
    "                    vfrozen_tensor.int().to(device),\n",
    "                    vsnr_tensor.float().to(device)\n",
    "                )\n",
    "                vloss = calculate_loss(\n",
    "                    vfrozen_tensor.to(device), \n",
    "                    vtarget_tensor.to(device), \n",
    "                    voutputs.to(device)\n",
    "                )\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        scheduler.step(avg_vloss)\n",
    "\n",
    "        # Save checkpoint if validation improves\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_dir = f'./checkpoints/config_{CONFIG_NO}'\n",
    "            os.makedirs(model_dir, exist_ok=True)  \n",
    "            model_path = f'{model_dir}/model_epoch_{epoch}.pt'\n",
    "            \n",
    "            torch.save({\n",
    "                \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "                'model_config': {\n",
    "                    \"d_model\": model.d_model,\n",
    "                    \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                    \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                    \"seq_len\": model.seq_len,\n",
    "                    \"d_state\": model.d_state,\n",
    "                    \"d_conv\": model.d_conv,\n",
    "                    \"expand\": model.expand,\n",
    "                },\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_loss,\n",
    "                'val_loss': avg_vloss,\n",
    "                'state_dict': model.state_dict()\n",
    "            }, model_path)\n",
    "\n",
    "    print(\"Training completed. Model available to use\")\n",
    "\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        # Extracting tensors\n",
    "        channel_tensor, frozen_tensor, snr_tensor, target_tensor = data\n",
    "        ip1 = channel_tensor.float().to(device)\n",
    "        ip2 = frozen_tensor.int().to(device)\n",
    "        ip3 = snr_tensor.float().to(device)\n",
    "    \n",
    "\n",
    "        op = target_tensor.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ip1,ip2 ,ip3 ).to(device)\n",
    "\n",
    "\n",
    "        \n",
    "        loss = calculate_loss(ip2, op, outputs)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i%1000 == 999:\n",
    "            last_loss = running_loss/1000\n",
    "            print('  batch {} loss: {}\\n'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "    return last_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f26fb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train(epochs=50):\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "        # Training\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(epoch)\n",
    "\n",
    "        # Validation\n",
    "        running_vloss = 0.0\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(test_dataloader):\n",
    "                vchannel_tensor, vfrozen_tensor, vsnr_tensor, vtarget_tensor = vdata\n",
    "                voutputs = model(\n",
    "                    vchannel_tensor.float().to(device),\n",
    "                    vfrozen_tensor.int().to(device),\n",
    "                    vsnr_tensor.float().to(device)\n",
    "                )\n",
    "                vloss = calculate_loss(\n",
    "                    vfrozen_tensor.to(device), \n",
    "                    vtarget_tensor.to(device), \n",
    "                    voutputs.to(device)\n",
    "                )\n",
    "                running_vloss += vloss\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "        scheduler.step(avg_vloss)\n",
    "\n",
    "        # Save checkpoint if validation improves\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            model_dir = f'./checkpoints/config_{CONFIG_NO}'\n",
    "            os.makedirs(model_dir, exist_ok=True)  \n",
    "            model_path = f'{model_dir}/model_epoch_{epoch}.pt'\n",
    "            \n",
    "            torch.save({\n",
    "                \"comments\": \"Removed the snr as input entirely. (even if used in future, use as snr linear, not in db)\",\n",
    "                'model_config': {\n",
    "                    \"d_model\": model.d_model,\n",
    "                    \"num_layer_encoder\": model.num_layer_encoder,\n",
    "                    \"num_layers_bimamba_block\": model.num_layers_bimamba_block,\n",
    "                    \"seq_len\": model.seq_len,\n",
    "                    \"d_state\": model.d_state,\n",
    "                    \"d_conv\": model.d_conv,\n",
    "                    \"expand\": model.expand,\n",
    "                },\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': avg_loss,\n",
    "                'val_loss': avg_vloss,\n",
    "                'state_dict': model.state_dict()\n",
    "            }, model_path)\n",
    "\n",
    "    print(\"Training completed. Model available to use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d589f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 0.2502212539166212\n",
      "\n",
      "  batch 2000 loss: 0.23981824016571046\n",
      "\n",
      "  batch 3000 loss: 0.23192114596068858\n",
      "\n",
      "LOSS train 0.23192114596068858 valid 0.25417956709861755\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.22702310258150102\n",
      "\n",
      "  batch 2000 loss: 0.22351305003464222\n",
      "\n",
      "  batch 3000 loss: 0.21982984371483327\n",
      "\n",
      "LOSS train 0.21982984371483327 valid 0.23638534545898438\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.21557194909453392\n",
      "\n",
      "  batch 2000 loss: 0.21754949006438257\n",
      "\n",
      "  batch 3000 loss: 0.21735527969896792\n",
      "\n",
      "LOSS train 0.21735527969896792 valid 0.23846088349819183\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.21491864542663097\n",
      "\n",
      "  batch 2000 loss: 0.21345287929475307\n",
      "\n",
      "  batch 3000 loss: 0.21316408875584603\n",
      "\n",
      "LOSS train 0.21316408875584603 valid 0.24101512134075165\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.2133659234121442\n",
      "\n",
      "  batch 2000 loss: 0.21201186206936837\n",
      "\n",
      "  batch 3000 loss: 0.21262901285290717\n",
      "\n",
      "LOSS train 0.21262901285290717 valid 0.2327154278755188\n",
      "EPOCH 6:\n",
      "  batch 1000 loss: 0.21308745166659354\n",
      "\n",
      "  batch 2000 loss: 0.21013671541959048\n",
      "\n",
      "  batch 3000 loss: 0.21281562393903733\n",
      "\n",
      "LOSS train 0.21281562393903733 valid 0.23358723521232605\n",
      "EPOCH 7:\n",
      "  batch 1000 loss: 0.21243155474215747\n",
      "\n",
      "  batch 2000 loss: 0.20940102031081914\n",
      "\n",
      "  batch 3000 loss: 0.21125584610551595\n",
      "\n",
      "LOSS train 0.21125584610551595 valid 0.24130313098430634\n",
      "EPOCH 8:\n",
      "  batch 1000 loss: 0.21201599380373956\n",
      "\n",
      "  batch 2000 loss: 0.21078965386748313\n",
      "\n",
      "  batch 3000 loss: 0.2092599333897233\n",
      "\n",
      "LOSS train 0.2092599333897233 valid 0.23721721768379211\n",
      "EPOCH 9:\n",
      "  batch 1000 loss: 0.2100451798737049\n",
      "\n",
      "  batch 2000 loss: 0.21014826546609403\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(epochs)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[32m     10\u001b[39m model.train(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m avg_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[32m     14\u001b[39m running_vloss = \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(epoch_index)\u001b[39m\n\u001b[32m     15\u001b[39m op = target_tensor.to(device)\n\u001b[32m     16\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mip1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mip2\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mip3\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     21\u001b[39m loss = calculate_loss(ip2, op, outputs)\n\u001b[32m     23\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/wrappers/mamba_32bits.py:114\u001b[39m, in \u001b[36mMambaPolarDecoder.forward\u001b[39m\u001b[34m(self, channel_ob_vector, frozen_prior, SNR_db)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# BiMamba encoder stack\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.encoder_layers):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     x_new = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     x = x_new * \u001b[38;5;28mself\u001b[39m.residual_scale + x\n\u001b[32m    116\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.post_norms[idx](x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:164\u001b[39m, in \u001b[36mBiMambaEncoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# pass through stacked BiMambaBlocks\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     h = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.norm(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:87\u001b[39m, in \u001b[36mBiMambaBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     out_f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_branch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpre_ln_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmamba_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpost_ln_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflip_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     out_r = \u001b[38;5;28mself\u001b[39m.forward_branch(x, \u001b[38;5;28mself\u001b[39m.pre_ln_r, \u001b[38;5;28mself\u001b[39m.mamba_r, \u001b[38;5;28mself\u001b[39m.post_ln_r, \u001b[38;5;28mself\u001b[39m.ffn_r, flip_time=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0.5\u001b[39m * (out_f + out_r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/src/models/base/bidirectional_mamba.py:70\u001b[39m, in \u001b[36mBiMambaBlock.forward_branch\u001b[39m\u001b[34m(self, x, pre_ln, mamba, post_ln, ffn, flip_time)\u001b[39m\n\u001b[32m     67\u001b[39m     x_proc = x\n\u001b[32m     69\u001b[39m h = pre_ln(x_proc)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m h = \u001b[43mmamba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m h = \u001b[38;5;28mself\u001b[39m.dropout(h)\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m flip_time:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/mamba_ssm/modules/mamba_simple.py:205\u001b[39m, in \u001b[36mMamba.forward\u001b[39m\u001b[34m(self, hidden_states, inference_params)\u001b[39m\n\u001b[32m    203\u001b[39m         ssm_state.copy_(last_state)\n\u001b[32m    204\u001b[39m     y = rearrange(y, \u001b[33m\"\u001b[39m\u001b[33mb d l -> b l d\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/5G-Polar/.venv/lib/python3.11/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae574987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your calc_save_ber function\n",
    "calc_save_ber(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    msg_bit_sizes=[8, 16, 24],\n",
    "    snr_db=[10, 6, 0, -6, -10],\n",
    "    num_samples=32_000,\n",
    "    batch_size=32,\n",
    "    json_file_name=\"evaluation_model_config_16\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
